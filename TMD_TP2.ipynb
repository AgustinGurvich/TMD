{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPIdK0Q581Vjq0UOlWmTYoo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AgustinGurvich/TMD/blob/main/TMD_TP2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports\n"
      ],
      "metadata": {
        "id": "eOqO7_NGkyiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages(\"randomForest\", dependencies = T)\n",
        "library(randomForest)\n",
        "install.packages(\"kernlab\", dependencies = T)\n",
        "library(kernlab)\n",
        "library(MASS)"
      ],
      "metadata": {
        "id": "Cah8nqnFk1OB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estimaciones de error"
      ],
      "metadata": {
        "id": "GvHrbGULWi7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#---------------------------------------------------------------------------\n",
        "#random forest error estimation (OOB) for greedy search\n",
        "#---------------------------------------------------------------------------\n",
        "rf.est <- function(x.train,y,equalize.classes=TRUE,tot.trees=500,mtry=0)\n",
        "{\n",
        "\tif(mtry<1) mtry<-floor(sqrt(dim(x.train)[2]))\n",
        "\tprop.samples<-table(y)\n",
        "\tif(equalize.classes) prop.samples<-rep(min(prop.samples),length(prop.samples))\n",
        "\treturn( randomForest(x.train,y,mtry=mtry,ntree=tot.trees,sampsize=prop.samples)$err.rate[tot.trees] )\n",
        "}\n",
        "\n",
        "#---------------------------------------------------------------------------\n",
        "#LDA error estimation (LOO) for greedy search\n",
        "#---------------------------------------------------------------------------\n",
        "lda.est <- function(x.train,y)\n",
        "{\n",
        "\tm.lda <- lda(x.train,y,CV=TRUE)\n",
        "\treturn(error.rate( y , m.lda$class))\n",
        "}\n",
        "error.rate <- function(dataA, dataB) sum( dataA != dataB ) / length(dataB)\n",
        "\n",
        "#---------------------------------------------------------------------------\n",
        "#SVM error estimation (internal CV) for greedy search\n",
        "#---------------------------------------------------------------------------\n",
        "svm.est <- function(x.train,y,type=\"C-svc\",kernel=\"vanilladot\",C=1,cross = 4)\n",
        "{\n",
        "\treturn ( ksvm(x.train, y, type=type,kernel=kernel,C=C,cross = cross)@cross )\n",
        "}\n",
        "\n",
        "#---------------------------------------------------------------------------\n",
        "#random forest ranking method for rfe.\n",
        "#---------------------------------------------------------------------------\n",
        "imp.rf <- function(x.train,y,equalize.classes=TRUE,tot.trees=500,mtry=0)\n",
        "{\n",
        "\tif(mtry<1) mtry<-floor(sqrt(dim(x.train)[2]))\n",
        "\tprop.samples<-table(y)\n",
        "\tif(equalize.classes) prop.samples<-rep(min(prop.samples),length(prop.samples))\n",
        "\t\n",
        "\tm.rf<-randomForest(x.train,y,ntree=tot.trees,mtry=mtry,sampsize=prop.samples,importance=TRUE)\n",
        "\timp.mat<-importance(m.rf)\n",
        "\timp.col<-dim(imp.mat)[2]-1\n",
        "\trank.list<-sort(imp.mat[,imp.col],decreasing=FALSE,index=T)\n",
        "\treturn(list(feats=rank.list$ix,imp=rank.list$x))\n",
        "}\n",
        "\n",
        "\n",
        "#---------------------------------------------------------------------------\n",
        "#linear svm ranking method for rfe. Using kernlab. Multiclass\n",
        "#---------------------------------------------------------------------------\n",
        "imp.linsvm <- function(x.train,y,C=100)\n",
        "{\n",
        "\tnum.feat<-dim(x.train)[2]\n",
        "\ttot.problems<-nlevels(y)*(nlevels(y)-1)/2\n",
        "\n",
        "\tm.svm <- ksvm(as.matrix(x.train), y, type=\"C-svc\",kernel=\"vanilladot\",C=C)\n",
        "\n",
        "\tw<-rep(0.0,num.feat)\n",
        "\tfor(i in 1:tot.problems) for(feat in 1:num.feat)\n",
        "\t\tw[feat]<-w[feat]+abs(m.svm@coef[[i]] %*% m.svm@xmatrix[[i]][,feat])\n",
        "\trank.list<-sort(w,decreasing=FALSE,index=T)\n",
        "\treturn(list(feats=rank.list$ix,imp=rank.list$x))\n",
        "}\n"
      ],
      "metadata": {
        "id": "_ulxu3_uWiuR"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Codigo para el wrapper greedy forward"
      ],
      "metadata": {
        "id": "210t7b3vRrDT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "3uGtnp7wRmRN"
      },
      "outputs": [],
      "source": [
        "#-------------------------------------------------------------------------------------\n",
        "# AVISO: este codigo esta adaptado de un paquete mayor. \n",
        "# No es optimo y tiene cosas inutiles para nosotros. Es un ejemplo nada mas\n",
        "#\n",
        "#general forward greedy selection function\n",
        "#input:\n",
        "# x,y inputs and targets\n",
        "# method is an external function that estimates classification error with a given model\n",
        "# ... parameters for method\n",
        "#output:\n",
        "#ordered.names.list <- nombre de las variables ordenadas de la mas importante a la menos\n",
        "#ordered.features.list <-numero de orden inicial de las variables, con el mismo orden\n",
        "#importance <- importancia de cada variables en el mismo orden\n",
        "\n",
        "#-------------------------------------------------------------------------------------\n",
        "forward.ranking <- function(x,y,method,verbosity=0,... )\n",
        "{\n",
        "\n",
        "\tmax.feat<-dim(x)[2] #Cantidad de variables (digamosle k)\n",
        "\tnum.feat<-1 #Cantidad inicial de variables\n",
        "\tlist.feat<-1:max.feat #Sequencia de 1 a k donde guardo las variables mas importantes\n",
        "\n",
        "\t#ranking inicial: elijo la variable con menor error de prediccion\n",
        "  x.train<-matrix(0,dim(x)[1],1) #Columna de 0 de tamaÃ±o n \n",
        "\tclass.error<-double(max.feat) #Aca voy a guardar todos los errores\n",
        "\t#para cada i, creo el dataset con esa variable sola, entreno un modelo y le mido el error, que lo guardo en class.error[i]\n",
        "\tfor(i in 1:max.feat){\n",
        "\t\tx.train[,1]<-x[,i] #Lleno la variable donde guardo los datos de train con la columna de la variable que me importa\n",
        "\t\tclass.error[i] <- do.call(method, c(list(as.matrix(x.train), y), list(...)) ) # Entreno un modelo y guardo el error\n",
        "\t}\n",
        "\t#guardo la variable con minimo error como primera. Guardo una lista keep.feat con las que me quedan para seguir eligiendo.\n",
        "\tlist.feat[1]<-which.min(class.error) #Aca quedan ordenadas por importancia\n",
        "\tkeep.feat<-sort(class.error,decreasing=FALSE,index=T)$ix[-1] #Aca quedan las que tengo que probar\n",
        "\t#armo un dataset con las variables que ya elegi, para ir agregando en cada paso.\n",
        "\tx.prev<-x.train[,1]<-x[,list.feat[1]] #En x.train pongo la variable importante como columna, y guardo esa columna como variable en x.prev\n",
        "\n",
        "\tif(verbosity>1) cat(\"\\nFirst feature: \",list.feat[1],\"\\n\")\n",
        "\n",
        "    #loop principal. A cada paso agrego todas las variables disponibles, de a una, le mido el error y me quedo con la de minimo error. Hasta llegar a meter todas.\n",
        "\twhile(num.feat<max.feat){\n",
        "    #class.error guarda el error de cada modelo. Son max.feat-num.feat modelos.\n",
        "\t\tclass.error<-double(max.feat-num.feat) #Voy sacando features\n",
        "\t\t#para cada variable que me queda, la agrego al dataset del paso anterior, entreno el modelo y le mido el error.\n",
        "\t\tfor(i in 1:(max.feat-num.feat)){\n",
        "\t\t\tx.train<-cbind(x.prev,x[,keep.feat[i]]) #En x.prev estaban las variables que me servian, le agrego como columna la nueva variable \n",
        "\t\t\tclass.error[i] <- do.call(method, c(list(as.matrix(x.train), y), list(...)) )\n",
        "\t\t}\n",
        "\t\tif(verbosity>2) cat(\"\\nFeatures:\\n\",keep.feat,\"\\nErrors:\\n\",class.error)\n",
        "\t\t#me quedo con el modelo de minimo error, guardo ese feature en la lista de las elegidas, lo saco de la lista de las que quedan, y actualizo el dataset de partida de la iteracion.\n",
        "\t\tbest.index<-which.min(class.error)\n",
        "\t\tlist.feat[num.feat+1]<-keep.feat[best.index]\n",
        "\t\tif(verbosity>1) cat(\"\\n---------\\nStep \",1+num.feat,\"\\nFeature \",best.index)\n",
        "\n",
        "\t\tkeep.feat<-keep.feat[-best.index]\n",
        "\t\tif(verbosity>2) cat(\"\\nNew search list: \",keep.feat)\n",
        "\t\tnum.feat<-num.feat+1\n",
        "\t\tx.prev<-x[,list.feat[1:num.feat]] #Como en list.feat estaban las que me servian, ordenadas, las guardo en x.prev\n",
        "\t}\n",
        "\n",
        "\tprint(list.feat)\n",
        "\tsearch.names<-colnames(x)[list.feat]\n",
        "\t#le asigno a cada feature una importacia proporcional al orden en que lo seleccionamos\n",
        "\timp<-(max.feat:1)/max.feat\n",
        "\tnames(imp)<-search.names\n",
        "\n",
        "\tif(verbosity>1){\n",
        "\t\tcat(\"\\n---------\\nFinal ranking \",num.feat,\" features.\")\n",
        "\t\tcat(\"\\nFeatures: \",search.names,\"\\n\")\n",
        "\t}\n",
        "\n",
        " \treturn( list(ordered.names.list=search.names,ordered.features.list=list.feat,importance=imp) )\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Codigo para el wrapper greedy backward"
      ],
      "metadata": {
        "id": "seaLOKDiY-O7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "backward.ranking <- function(data, classes, method, ...){\n",
        "\tfeature_amount = dim(data)[2]\n",
        "\tfeature_list = 1 : feature_amount\n",
        "\t# Lista donde se guardarÃ¡n los features en orden de eliminaciÃ³n.\n",
        "\tfeature_removal_order = double(feature_amount)\n",
        "\t  \n",
        "\t# Iteraremos hasta haber eliminado todos los features excepto uno.\n",
        "\twhile(length(feature_list) > 1){\n",
        "\t\t# Almacenaremos tantas estimaciones de error como features nos queden en la iteraciÃ³n.\n",
        "\t\terror_estimations = double(length(feature_list))\n",
        "\t\t# Por cada feature que nos queda, estimaremos el error de entrenar un mÃ©todo usando\n",
        "\t\t# todos los demÃ¡s menos Ã©l.\n",
        "\t\tfor(feature_index in 1 : length(feature_list)){\n",
        "\t\t\ttraining_data = as.matrix(data[, feature_list[-feature_index]])\n",
        "\t\t\terror_estimations[feature_index] = do.call(method, c(list(training_data, classes), list(...)))\n",
        "\t\t}\n",
        "\t\t\n",
        "\t\t# Eliminamos el feature que, al entrenar sin Ã©l, nos resulta en el error mÃ­nimo\n",
        "\t\t# entre todas las opciones.\n",
        "\t\tfeature_to_remove = which.min(error_estimations)\n",
        "\t\tfeature_removal_order[length(feature_list)] = feature_list[feature_to_remove]\n",
        "\t\tfeature_list = feature_list[- feature_to_remove]\n",
        "\t}\n",
        "\t\n",
        "\t# El Ãºltimo feature en eliminar es el que haya quedado de las iteraciones anteriores.\n",
        "\tfeature_removal_order[1] = feature_list[1]\n",
        "\t\n",
        "\t# Luego, preparamos la informaciÃ³n para que se devuelva con el mismo formato que \n",
        "\t# tiene el mÃ©todo de base que estaba dado.\n",
        "\tfeature_names = colnames(data)[feature_removal_order]\n",
        "\timportance = (feature_amount : 1) / feature_amount\n",
        "\tnames(importance) = feature_names\n",
        "\t\n",
        " \treturn(list(ordered.names.list = feature_names, \n",
        " \t            ordered.features.list = feature_removal_order, \n",
        " \t            importance = importance))\n",
        "}"
      ],
      "metadata": {
        "id": "dwRBAn5jZAY6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Codigo para el filter con test no-paramÃ©trico"
      ],
      "metadata": {
        "id": "yCGk6lez8rMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "no.parametrico <- function(x,y){\n",
        "  var.count <- dim(x)[2]\n",
        "  stat <- c()\n",
        "  for (i in 1:var.count){\n",
        "    var<-x[,i]\n",
        "    stat[i] <- kruskal.test(var,y)$statistic\n",
        "  }\n",
        "  ordered.vars <- order(stat, decreasing=T) \n",
        "  var.names<-colnames(x)[ordered.vars]\n",
        "  imp<-(var.count:1)/var.count\n",
        "\tnames(imp)<-var.names\n",
        "  return( list(ordered.names.list=var.names,ordered.features.list=ordered.vars,importance=imp) )\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "LAVHPE748upw"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Codigo para el RFE"
      ],
      "metadata": {
        "id": "G5n-EIDTjeXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rfe <- function(x,y,method,...){\n",
        "  p <- dim(x)[2]\n",
        "  F <- 1:p #Todas mis variables\n",
        "  R <- c()\n",
        "  for(i in 1:p){\n",
        "    #Truco que me sirvio para entender que estoy haciendo al construir el dataset de entrenamiento:\n",
        "    #F es una lista de indices (guarda todas las variables que voy a usar)\n",
        "    #En lugar de hacer algun truco raro para llevar registro de que voy eliminando, reconstruyo el dataset de entrenamiento con los indices\n",
        "    x.train <- as.matrix(x[,F]) #Tengo que pasarlo a matrix porque sino tengo problemas con las dimensiones\n",
        "    values <- do.call(method, c(list(x,train, y), list(...)) ) \n",
        "    fIndex <- values$feats[1] #Obtengo la variable menos importante\n",
        "    R[p-i+1] <- F[fIndex] #Agrego la variable menos importante\n",
        "    F <- F[-fIndex] #Elimino la variable de mi lista de variables\n",
        "  }\n",
        "  var.names<-colnames(x)[R]\n",
        "  imp<-(p:1)/p\n",
        "\tnames(imp)<-var.names\n",
        "  return( list(ordered.names.list=var.names,ordered.features.list=R,importance=imp) )\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "s6_ICXk2h1JZ"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplicamos cada analisis"
      ],
      "metadata": {
        "id": "Je1vi7_iRu0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#demo: aplicar el wrapper a los datos de iris\n",
        "data(iris)"
      ],
      "metadata": {
        "id": "ad5WW4wrs_dY"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FORW.rf <-forward.ranking(iris[,-5],iris[,5],method=\"rf.est\" ,tot.trees=100,equalize.classes=F)\n",
        "FORW.lda<-forward.ranking(iris[,-5],iris[,5],method=\"lda.est\")\n",
        "print(FORW.rf)\n",
        "print(FORW.lda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNEicfdss3Tn",
        "outputId": "b59232f3-d03e-4206-afc7-ddabdaa6a0b2"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] 4 3 1 2\n",
            "[1] 4 3 1 2\n",
            "$ordered.names.list\n",
            "[1] \"Petal.Width\"  \"Petal.Length\" \"Sepal.Length\" \"Sepal.Width\" \n",
            "\n",
            "$ordered.features.list\n",
            "[1] 4 3 1 2\n",
            "\n",
            "$importance\n",
            " Petal.Width Petal.Length Sepal.Length  Sepal.Width \n",
            "        1.00         0.75         0.50         0.25 \n",
            "\n",
            "$ordered.names.list\n",
            "[1] \"Petal.Width\"  \"Petal.Length\" \"Sepal.Length\" \"Sepal.Width\" \n",
            "\n",
            "$ordered.features.list\n",
            "[1] 4 3 1 2\n",
            "\n",
            "$importance\n",
            " Petal.Width Petal.Length Sepal.Length  Sepal.Width \n",
            "        1.00         0.75         0.50         0.25 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BACK.rf <-backward.ranking(iris[,-5],iris[,5],method=\"rf.est\" ,tot.trees=100,equalize.classes=F)\n",
        "print(BACK.rf)\n",
        "BACK.lda<-backward.ranking(iris[,-5],iris[,5],method=\"lda.est\")\n",
        "print(BACK.lda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hTvYXlzs6B_",
        "outputId": "166dd787-316a-4cb9-c2a1-43b6511daf36"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "$ordered.names.list\n",
            "[1] \"Petal.Width\"  \"Petal.Length\" \"Sepal.Width\"  \"Sepal.Length\"\n",
            "\n",
            "$ordered.features.list\n",
            "[1] 4 3 2 1\n",
            "\n",
            "$importance\n",
            " Petal.Width Petal.Length  Sepal.Width Sepal.Length \n",
            "        1.00         0.75         0.50         0.25 \n",
            "\n",
            "$ordered.names.list\n",
            "[1] \"Petal.Width\"  \"Petal.Length\" \"Sepal.Length\" \"Sepal.Width\" \n",
            "\n",
            "$ordered.features.list\n",
            "[1] 4 3 1 2\n",
            "\n",
            "$importance\n",
            " Petal.Width Petal.Length Sepal.Length  Sepal.Width \n",
            "        1.00         0.75         0.50         0.25 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noP <- no.parametrico(iris[,-5],iris[,5])\n",
        "print(noP)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9N3JFyg7s-AA",
        "outputId": "f82d0e4f-ea60-4e6d-adb6-9b54ddb53d2f"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "$ordered.names.list\n",
            "[1] \"Petal.Width\"  \"Petal.Length\" \"Sepal.Length\" \"Sepal.Width\" \n",
            "\n",
            "$ordered.features.list\n",
            "[1] 4 3 1 2\n",
            "\n",
            "$importance\n",
            " Petal.Width Petal.Length Sepal.Length  Sepal.Width \n",
            "        1.00         0.75         0.50         0.25 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RFE.rf <- rfe(iris[,-5],iris[,5],method=\"imp.rf\",tot.trees=100,equalize.classes=F)\n",
        "print(RFE.rf)\n",
        "RFE.linsvm <- rfe(iris[,-5],iris[,5],method=\"imp.linsvm\")\n",
        "print(RFE.linsvm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w34ux8tWW5a_",
        "outputId": "2c735901-2da2-4924-c78f-bff8b9724eb8"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "$ordered.names.list\n",
            "[1] \"Petal.Length\" \"Petal.Width\"  \"Sepal.Length\" \"Sepal.Width\" \n",
            "\n",
            "$ordered.features.list\n",
            "[1] 3 4 1 2\n",
            "\n",
            "$importance\n",
            "Petal.Length  Petal.Width Sepal.Length  Sepal.Width \n",
            "        1.00         0.75         0.50         0.25 \n",
            "\n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            "$ordered.names.list\n",
            "[1] \"Petal.Length\" \"Petal.Width\"  \"Sepal.Length\" \"Sepal.Width\" \n",
            "\n",
            "$ordered.features.list\n",
            "[1] 3 4 1 2\n",
            "\n",
            "$importance\n",
            "Petal.Length  Petal.Width Sepal.Length  Sepal.Width \n",
            "        1.00         0.75         0.50         0.25 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "crea.ruido.unif<-function(n=100,d=2){\n",
        "  x<-runif(2*n*d,min=-1)\t#genero los datos\n",
        "  dim(x)<-c(2*n,d)\n",
        "  return(cbind(as.data.frame(x),y=factor(rep(c(-1,1),each=n))))\t#le agrego la clase\n",
        "}\n",
        "\n",
        "#datosA\n",
        "d<-10\n",
        "n<-1000\n",
        "datos<-crea.ruido.unif(n=n,d=d)\n",
        "\n",
        "#tomar 50% de los datos al azar, y hacer que la clase sea el signo de la 8 variable\n",
        "shuffle<-sample(1:dim(datos)[1])\n",
        "sub<-shuffle[1:dim(datos)[1]*0.5]\n",
        "datos[sub,d+1]<-sign(datos[sub,8])\n",
        "#tomar 20% de los datos al azar (fuera de los anteriores), y hacer que la clase sea el signo de la 6 variable\n",
        "sub<-shuffle[(dim(datos)[1]*0.5):(dim(datos)[1]*0.7)]\n",
        "datos[sub,d+1]<-sign(datos[sub,6])\n",
        "#tomar 10% de los datos al azar, y hacer que la clase sea el signo de la 4 variable\n",
        "sub<-shuffle[(dim(datos)[1]*0.7):(dim(datos)[1]*0.8)]\n",
        "datos[sub,d+1]<-sign(datos[sub,4])\n",
        "#tomar 5% de los datos al azar, y hacer que la clase sea el signo de la 2 variable\n",
        "sub<-shuffle[(dim(datos)[1]*0.8):(dim(datos)[1]*0.85)]\n",
        "datos[sub,d+1]<-sign(datos[sub,2])\n",
        "datos[,d+1]<-factor(datos[,d+1])\n",
        "\n",
        "datosA<-datos\n",
        "\n",
        "#datosB\n",
        "#generar n=100,d=8\n",
        "d<-8\n",
        "n<-1000\n",
        "datos<-crea.ruido.unif(n=n,d=d)\n",
        "#hacer que la clase sea el xor de las 2 primeras variables (es usando el signo)\n",
        "datos[,d+1]<-sign(datos[,1]*datos[,2])\n",
        "#hacer que las variables 3 y 4 tengan un 50% de correlacion con la clase\n",
        "shuffle<-sample(1:dim(datos)[1])\n",
        "sub<-shuffle[1:dim(datos)[1]*0.5]\n",
        "datos[sub,3]<-abs(datos[sub,3])*datos[sub,d+1]\n",
        "shuffle<-sample(1:dim(datos)[1])\n",
        "sub<-shuffle[1:dim(datos)[1]*0.5]\n",
        "datos[sub,4]<-abs(datos[sub,4])*datos[sub,d+1]\n",
        "datos[,d+1]<-factor(datos[,d+1])\n",
        "\n",
        "datosB<-datos"
      ],
      "metadata": {
        "id": "L2wYpiq6RwUv"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Aplicamos los metodos de seleccion de variables sobre datosA"
      ],
      "metadata": {
        "id": "K6QAcPd41ZUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datosA.FORW.svm<-forward.ranking(datosA[,-11],datosA[,11],method=\"svm.est\",)\n",
        "print(\"Resultado con FORW.svm\")\n",
        "print(datosA.FORW.svm$importance)\n",
        "datosA.FORW.rf <-forward.ranking(datosA[,-11],datosA[,11],method=\"rf.est\" ,tot.trees=100,equalize.classes=F)\n",
        "print(\"Resultado con FORW.rf\")\n",
        "print(datosA.FORW.rf$importance)\n",
        "datosA.FORW.lda<-forward.ranking(datosA[,-11],datosA[,11],method=\"lda.est\")\n",
        "print(\"Resultado con FORW.lda\")\n",
        "print(datosA.FORW.lda$importance)\n",
        "\n",
        "datosA.BACK.svm<-backward.ranking(datosA[,-11],datosA[,11],method=\"svm.est\")\n",
        "print(\"Resultado con BACK.svm\")\n",
        "print(datosA.FORW.svm$importance)\n",
        "datosA.BACK.rf <-backward.ranking(datosA[,-11],datosA[,11],method=\"rf.est\" ,tot.trees=100,equalize.classes=F)\n",
        "print(\"Resultado con BACK.rf\")\n",
        "print(datosA.BACK.rf$importance)\n",
        "datosA.BACK.lda<-backward.ranking(datosA[,-11],datosA[,11],method=\"lda.est\")\n",
        "print(\"Resultado con BACK.lda\")\n",
        "print(datosA.BACK.lda$importance)\n",
        "\n",
        "datosA.noP <- no.parametrico(datosA[,-11],datosA[,11])\n",
        "print(\"Resultado con noP\")\n",
        "print(datosA.noP$importance)\n",
        "\n",
        "datosA.RFE.rf <- rfe(datosA[,-11],datosA[,11],method=\"imp.rf\",tot.trees=100,equalize.classes=F)\n",
        "print(\"Resultado con RFE.rf\")\n",
        "print(datosA.RFE.rf$importance)\n",
        "datosA.RFE.linsvm <- rfe(datosA[,-11],datosA[,11],method=\"imp.linsvm\")\n",
        "print(\"Resultado con RFE.linsvm\")\n",
        "print(datosA.RFE.linsvm$importance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vk5s27pb5iMM",
        "outputId": "4eb4e4b8-90dc-4535-acf9-eaae5e06393d"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " [1]  8  5  1  3 10  9  6  4  2  7\n",
            "[1] \"Resultado con FORW.svm\"\n",
            " V8  V5  V1  V3 V10  V9  V6  V4  V2  V7 \n",
            "1.0 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 \n",
            " [1]  8 10  3  4  5  7  1  6  9  2\n",
            "[1] \"Resultado con FORW.rf\"\n",
            " V8 V10  V3  V4  V5  V7  V1  V6  V9  V2 \n",
            "1.0 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 \n",
            " [1]  8  1  2  5 10  9  6  4  7  3\n",
            "[1] \"Resultado con FORW.lda\"\n",
            " V8  V1  V2  V5 V10  V9  V6  V4  V7  V3 \n",
            "1.0 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            "[1] \"Resultado con BACK.svm\"\n",
            " V8  V5  V1  V3 V10  V9  V6  V4  V2  V7 \n",
            "1.0 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 \n",
            "[1] \"Resultado con BACK.rf\"\n",
            " V8 V10  V2  V4  V6  V7  V9  V5  V3  V1 \n",
            "1.0 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 \n",
            "[1] \"Resultado con BACK.lda\"\n",
            " V8  V4  V6 V10  V9  V2  V1  V7  V5  V3 \n",
            "1.0 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 \n",
            "[1] \"Resultado con noP\"\n",
            " V8  V6  V7  V1  V4  V9 V10  V3  V2  V5 \n",
            "1.0 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 \n",
            "[1] \"Resultado con RFE.rf\"\n",
            " V8  V6  V3  V7  V1  V9  V4 V10  V2  V5 \n",
            "1.0 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            "[1] \"Resultado con RFE.linsvm\"\n",
            " V8  V7  V6  V4  V2  V9  V3  V1 V10  V5 \n",
            "1.0 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "backward.ranking(iris[,-5],iris[,5],method=\"svm.est\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "LtidpmSa13AN",
        "outputId": "1508cf5d-546f-4fe7-fe0c-bcde21ebd754"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n",
            " Setting default kernel parameters  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<dl>\n",
              "\t<dt>$ordered.names.list</dt>\n",
              "\t\t<dd><style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>'Petal.Width'</li><li>'Petal.Length'</li><li>'Sepal.Width'</li><li>'Sepal.Length'</li></ol>\n",
              "</dd>\n",
              "\t<dt>$ordered.features.list</dt>\n",
              "\t\t<dd><style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>4</li><li>3</li><li>2</li><li>1</li></ol>\n",
              "</dd>\n",
              "\t<dt>$importance</dt>\n",
              "\t\t<dd><style>\n",
              ".dl-inline {width: auto; margin:0; padding: 0}\n",
              ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
              ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
              ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
              "</style><dl class=dl-inline><dt>Petal.Width</dt><dd>1</dd><dt>Petal.Length</dt><dd>0.75</dd><dt>Sepal.Width</dt><dd>0.5</dd><dt>Sepal.Length</dt><dd>0.25</dd></dl>\n",
              "</dd>\n",
              "</dl>\n"
            ],
            "text/markdown": "$ordered.names.list\n:   1. 'Petal.Width'\n2. 'Petal.Length'\n3. 'Sepal.Width'\n4. 'Sepal.Length'\n\n\n\n$ordered.features.list\n:   1. 4\n2. 3\n3. 2\n4. 1\n\n\n\n$importance\n:   Petal.Width\n:   1Petal.Length\n:   0.75Sepal.Width\n:   0.5Sepal.Length\n:   0.25\n\n\n\n\n",
            "text/latex": "\\begin{description}\n\\item[\\$ordered.names.list] \\begin{enumerate*}\n\\item 'Petal.Width'\n\\item 'Petal.Length'\n\\item 'Sepal.Width'\n\\item 'Sepal.Length'\n\\end{enumerate*}\n\n\\item[\\$ordered.features.list] \\begin{enumerate*}\n\\item 4\n\\item 3\n\\item 2\n\\item 1\n\\end{enumerate*}\n\n\\item[\\$importance] \\begin{description*}\n\\item[Petal.Width] 1\n\\item[Petal.Length] 0.75\n\\item[Sepal.Width] 0.5\n\\item[Sepal.Length] 0.25\n\\end{description*}\n\n\\end{description}\n",
            "text/plain": [
              "$ordered.names.list\n",
              "[1] \"Petal.Width\"  \"Petal.Length\" \"Sepal.Width\"  \"Sepal.Length\"\n",
              "\n",
              "$ordered.features.list\n",
              "[1] 4 3 2 1\n",
              "\n",
              "$importance\n",
              " Petal.Width Petal.Length  Sepal.Width Sepal.Length \n",
              "        1.00         0.75         0.50         0.25 \n"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}