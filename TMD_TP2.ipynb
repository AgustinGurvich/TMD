{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFo2D0WzNUMVFY2EJixiuI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AgustinGurvich/TMD/blob/main/TMD_TP2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estimaciones de error"
      ],
      "metadata": {
        "id": "GvHrbGULWi7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#---------------------------------------------------------------------------\n",
        "#random forest error estimation (OOB) for greedy search\n",
        "#---------------------------------------------------------------------------\n",
        "rf.est <- function(x.train,y,equalize.classes=TRUE,tot.trees=500,mtry=0)\n",
        "{\n",
        "\tif(mtry<1) mtry<-floor(sqrt(dim(x.train)[2]))\n",
        "\tprop.samples<-table(y)\n",
        "\tif(equalize.classes) prop.samples<-rep(min(prop.samples),length(prop.samples))\n",
        "\treturn( randomForest(x.train,y,mtry=mtry,ntree=tot.trees,sampsize=prop.samples)$err.rate[tot.trees] )\n",
        "}\n",
        "\n",
        "#---------------------------------------------------------------------------\n",
        "#LDA error estimation (LOO) for greedy search\n",
        "#---------------------------------------------------------------------------\n",
        "lda.est <- function(x.train,y)\n",
        "{\n",
        "\tm.lda <- lda(x.train,y,CV=TRUE)\n",
        "\treturn(error.rate( y , m.lda$class))\n",
        "}\n",
        "error.rate <- function(dataA, dataB) sum( dataA != dataB ) / length(dataB)\n",
        "\n",
        "#---------------------------------------------------------------------------\n",
        "#SVM error estimation (internal CV) for greedy search\n",
        "#---------------------------------------------------------------------------\n",
        "svm.est <- function(x.train,y,type=\"C-svc\",kernel=\"vanilladot\",C=1,cross = 4)\n",
        "{\n",
        "\treturn ( ksvm(x.train, y, type=type,kernel=kernel,C=C,cross = cross)@cross )\n",
        "}\n",
        "\n",
        "#---------------------------------------------------------------------------\n",
        "#random forest error estimation (OOB) for greedy search\n",
        "#---------------------------------------------------------------------------\n",
        "rf.est <- function(x.train,y,equalize.classes=TRUE,tot.trees=500,mtry=0)\n",
        "{\n",
        "\tif(mtry<1) mtry<-floor(sqrt(dim(x.train)[2]))\n",
        "\tprop.samples<-table(y)\n",
        "\tif(equalize.classes) prop.samples<-rep(min(prop.samples),length(prop.samples))\n",
        "\treturn( randomForest(x.train,y,mtry=mtry,ntree=tot.trees,sampsize=prop.samples)$err.rate[tot.trees] )\n",
        "}\n",
        "\n",
        "#---------------------------------------------------------------------------\n",
        "#LDA error estimation (LOO) for greedy search\n",
        "#---------------------------------------------------------------------------\n",
        "lda.est <- function(x.train,y)\n",
        "{\n",
        "\tm.lda <- lda(x.train,y,CV=TRUE)\n",
        "\treturn(error.rate( y , m.lda$class))\n",
        "}\n",
        "error.rate <- function(dataA, dataB) sum( dataA != dataB ) / length(dataB)\n",
        "\n",
        "#---------------------------------------------------------------------------\n",
        "#SVM error estimation (internal CV) for greedy search\n",
        "#---------------------------------------------------------------------------\n",
        "svm.est <- function(x.train,y,type=\"C-svc\",kernel=\"vanilladot\",C=1,cross = 4)\n",
        "{\n",
        "\treturn ( ksvm(x.train, y, type=type,kernel=kernel,C=C,cross = cross)@cross )\n",
        "}\n"
      ],
      "metadata": {
        "id": "_ulxu3_uWiuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Codigo para el wrapper greedy forward"
      ],
      "metadata": {
        "id": "210t7b3vRrDT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3uGtnp7wRmRN"
      },
      "outputs": [],
      "source": [
        "#-------------------------------------------------------------------------------------\n",
        "# AVISO: este codigo esta adaptado de un paquete mayor. \n",
        "# No es optimo y tiene cosas inutiles para nosotros. Es un ejemplo nada mas\n",
        "#\n",
        "#general forward greedy selection function\n",
        "#input:\n",
        "# x,y inputs and targets\n",
        "# method is an external function that estimates classification error with a given model\n",
        "# ... parameters for method\n",
        "#output:\n",
        "#ordered.names.list <- nombre de las variables ordenadas de la mas importante a la menos\n",
        "#ordered.features.list <-numero de orden inicial de las variables, con el mismo orden\n",
        "#importance <- importancia de cada variables en el mismo orden\n",
        "\n",
        "#-------------------------------------------------------------------------------------\n",
        "forward.ranking <- function(x,y,method,verbosity=0,... )\n",
        "{\n",
        "\n",
        "\tmax.feat<-dim(x)[2] #Cantidad de variables (digamosle k)\n",
        "\tnum.feat<-1 #Cantidad inicial de variables\n",
        "\tlist.feat<-1:max.feat #Sequencia de 1 a k donde guardo las variables mas importantes\n",
        "\n",
        "\t#ranking inicial: elijo la variable con menor error de prediccion\n",
        "  x.train<-matrix(0,dim(x)[1],1) #Columna de 0 de tamaño n \n",
        "\tclass.error<-double(max.feat) #Aca voy a guardar todos los errores\n",
        "\t#para cada i, creo el dataset con esa variable sola, entreno un modelo y le mido el error, que lo guardo en class.error[i]\n",
        "\tfor(i in 1:max.feat){\n",
        "\t\tx.train[,1]<-x[,i] #Lleno la variable donde guardo los datos de train con la columna de la variable que me importa\n",
        "\t\tclass.error[i] <- do.call(method, c(list(x.train, y), list(...)) ) # Entreno un modelo y guardo el error\n",
        "\t}\n",
        "\t#guardo la variable con minimo error como primera. Guardo una lista keep.feat con las que me quedan para seguir eligiendo.\n",
        "\tlist.feat[1]<-which.min(class.error) #Aca quedan ordenadas por importancia\n",
        "\tkeep.feat<-sort(class.error,decreasing=FALSE,index=T)$ix[-1] #Aca quedan las que tengo que probar\n",
        "\t#armo un dataset con las variables que ya elegi, para ir agregando en cada paso.\n",
        "\tx.prev<-x.train[,1]<-x[,list.feat[1]] #En x.train pongo la variable importante como columna, y guardo esa columna como variable en x.prev\n",
        "\n",
        "\tif(verbosity>1) cat(\"\\nFirst feature: \",list.feat[1],\"\\n\")\n",
        "\n",
        "    #loop principal. A cada paso agrego todas las variables disponibles, de a una, le mido el error y me quedo con la de minimo error. Hasta llegar a meter todas.\n",
        "\twhile(num.feat<max.feat){\n",
        "    #class.error guarda el error de cada modelo. Son max.feat-num.feat modelos.\n",
        "\t\tclass.error<-double(max.feat-num.feat) #Voy sacando features\n",
        "\t\t#para cada variable que me queda, la agrego al dataset del paso anterior, entreno el modelo y le mido el error.\n",
        "\t\tfor(i in 1:(max.feat-num.feat)){\n",
        "\t\t\tx.train<-cbind(x.prev,x[,keep.feat[i]]) #En x.prev estaban las variables que me servian, le agrego como columna la nueva variable \n",
        "\t\t\tclass.error[i] <- do.call(method, c(list(x.train, y), list(...)) )\n",
        "\t\t}\n",
        "\t\tif(verbosity>2) cat(\"\\nFeatures:\\n\",keep.feat,\"\\nErrors:\\n\",class.error)\n",
        "\t\t#me quedo con el modelo de minimo error, guardo ese feature en la lista de las elegidas, lo saco de la lista de las que quedan, y actualizo el dataset de partida de la iteracion.\n",
        "\t\tbest.index<-which.min(class.error)\n",
        "\t\tlist.feat[num.feat+1]<-keep.feat[best.index]\n",
        "\t\tif(verbosity>1) cat(\"\\n---------\\nStep \",1+num.feat,\"\\nFeature \",best.index)\n",
        "\n",
        "\t\tkeep.feat<-keep.feat[-best.index]\n",
        "\t\tif(verbosity>2) cat(\"\\nNew search list: \",keep.feat)\n",
        "\t\tnum.feat<-num.feat+1\n",
        "\t\tx.prev<-x[,list.feat[1:num.feat]] #Como en list.feat estaban las que me servian, ordenadas, las guardo en x.prev\n",
        "\t}\n",
        "\n",
        "\tprint(list.feat)\n",
        "\tsearch.names<-colnames(x)[list.feat]\n",
        "\t#le asigno a cada feature una importacia proporcional al orden en que lo seleccionamos\n",
        "\timp<-(max.feat:1)/max.feat\n",
        "\tnames(imp)<-search.names\n",
        "\n",
        "\tif(verbosity>1){\n",
        "\t\tcat(\"\\n---------\\nFinal ranking \",num.feat,\" features.\")\n",
        "\t\tcat(\"\\nFeatures: \",search.names,\"\\n\")\n",
        "\t}\n",
        "\n",
        " \treturn( list(ordered.names.list=search.names,ordered.features.list=list.feat,importance=imp) )\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Codigo para el wrapper greedy backward"
      ],
      "metadata": {
        "id": "seaLOKDiY-O7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "backward.ranking <- function(x,y,method,verbosity=0,... )\n",
        "{\n",
        "\n",
        "\tmax.feat<-dim(x)[2] #Cantidad de variables (digamosle k)\n",
        "\tnum.feat<-0 #Cantidad de variables que saque (ninguna)\n",
        "\tlist.feat<-1:max.feat #Sequencia de 1 a k donde guardo las variables mas importantes\n",
        "\n",
        "\t#ranking inicial: entreno un modelo completo y le mido el error\n",
        "    x.train<-matrix(0,dim(x)[1],max.feat - num.feat)  \n",
        "\tx.train<-x #El primer entrenamiento se hace con todo el dataset\n",
        "\tprevious.error <- do.call(method, c(list(x.train, y), list(...)) ) # Entreno un modelo completo y guardo el error\n",
        "\n",
        "    class.error<-double(max.feat)\n",
        "    for(i in 1:max.feat){\n",
        "\t\tx.train<-x[,-i]\n",
        "\t\tclass.error[i] <- do.call(method, c(list(x.train, y), list(...)) )\n",
        "        class.error[i] <- abs(class.error[i] - previous.error) #Diferencia con el error anterior\n",
        "    }\n",
        "\n",
        "\n",
        "\t#Saco la variable que menos error me agrego (no era tan importante). Guardo una lista keep.feat con las que me quedan para seguir sacando.\n",
        "\tmin.error.index <- which.min(class.error) #La que menor error deja es la menos importante (no afecto que la saque) \n",
        "    previous.error <- class.error[min.error.index] #El modelo adecuado es este\n",
        "    list.feat[1]<-min.error.index #Aca quedan ordenadas por menor importancia\n",
        "\tkeep.feat<-sort(class.error,decreasing=FALSE,index=T)$ix[-1] #Aca quedan las que tengo que probar\n",
        "\t#Saco del dataset las variables que ya probe\n",
        "\tx.prev<-x.train[,-1]<-x[,-list.feat[1]] #En x.train pongo la variable importante como columna, y guardo esa columna como variable en x.prev\n",
        "    num.feat<-num.feat+1\n",
        "\n",
        "\tif(verbosity>1) cat(\"\\nFirst iteration completed. Removed feat: \",list.feat[1],\"\\n\")\n",
        "\n",
        "    #loop principal. A cada paso saco variables, de a una, le mido el error y elimino la de minimo error. Hasta llegar a sacar todas.\n",
        "\twhile(num.feat<max.feat){\n",
        "    print(num.feat)\n",
        "    print(keep.feat)\n",
        "        #class.error guarda el error de cada modelo. Son max.feat-num.feat modelos.\n",
        "\t\tclass.error<-double(max.feat-num.feat) #Voy sacando features\n",
        "\t\t#para cada variable que me queda, la saco del dataset del paso anterior, entreno el modelo y le mido el error.\n",
        "\t\tfor(i in 1:(max.feat-num.feat)){\n",
        "\t\t\tx.train<-x.prev[,-keep.feat[i]] #En x.prev estaban las variables que me servian, le saco como columna la nueva variable \n",
        "\t\t\tclass.error[i] <- do.call(method, c(list(x.train, y), list(...)) )\n",
        "\t\t\tclass.error[i] <- abs(class.error[i] - previous.error) #Diferencia con el error anterio\n",
        "\t\t}\n",
        "\t\tif(verbosity>2) cat(\"\\nFeatures:\\n\",keep.feat,\"\\nErrors:\\n\",class.error)\n",
        "\t\t#me quedo con el modelo de minimo error, guardo ese feature en la lista de las elegidas, lo saco de la lista de las que quedan, y actualizo el dataset de partida de la iteracion.\n",
        "\t\tmin.error.index<-which.min(class.error)\n",
        "\t\tprevious.error <- class.error[min.error.index]\n",
        "\t\tlist.feat[num.feat+1]<-keep.feat[min.error.index]\n",
        "\t\tif(verbosity>1) cat(\"\\n---------\\nStep \",1+num.feat,\"\\nFeature \",min.error.index)\n",
        "\n",
        "\t\tkeep.feat<-keep.feat[-min.error.index]\n",
        "\t\tif(verbosity>2) cat(\"\\nNew search list: \",keep.feat)\n",
        "\t\tnum.feat<-num.feat+1\n",
        "\t\tx.prev<-x.prev[,-list.feat[num.feat]] #Como en list.feat estaban las que me servian, ordenadas, las guardo en x.prev\n",
        "\t}\n",
        "\n",
        "\n",
        "\tsearch.names<-colnames(x)[list.feat]\n",
        "\t#le asigno a cada feature una importacia proporcional al orden en que lo seleccionamos\n",
        "\timp<-(max.feat:1)/max.feat\n",
        "\tnames(imp)<-search.names\n",
        "\n",
        "\tif(verbosity>1){\n",
        "\t\tcat(\"\\n---------\\nFinal ranking \",num.feat,\" features.\")\n",
        "\t\tcat(\"\\nFeatures: \",search.names,\"\\n\")\n",
        "\t}\n",
        "\n",
        " \treturn( list(ordered.names.list=search.names,ordered.features.list=list.feat,importance=imp) )\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "dwRBAn5jZAY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Codigo para el filter con test no-paramétrico"
      ],
      "metadata": {
        "id": "yCGk6lez8rMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "no.parametrico <- function(x,y){\n",
        "  var.count <- dim(x)[2]\n",
        "  stat <- matrix(ncol = var.count, nrow = 1)\n",
        "  for (i in 1:var.count){\n",
        "    var<-x[,i]\n",
        "    stat[1,i] <- kruskal.test(var,y)$statistic\n",
        "  }\n",
        "  ordered.vars <- order(stat, decreasing=T) \n",
        "  var.names<-colnames(x)[ordered.vars]\n",
        "  return( list(ordered.names.list=var.names,ordered.features.list=ordered.vars,importance=sort(stat,decreasing=T)) )\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "LAVHPE748upw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Codigo para el RFE con SVM"
      ],
      "metadata": {
        "id": "72J5LGTYhzIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfe <- function(x,y,method,...){\n",
        "  F <- x\n",
        "  p <- dim(x)[2]\n",
        "  R <- matrix(ncol = p, nrox = 1)\n",
        "  for(i in 1:p){\n",
        "    #¿Que es eso del metodo? Guardarlo en ranked\n",
        "    fIndex <- which.min(ranked) \n",
        "    R[1,p-i+1] <- fIndex\n",
        "    F <- F[,-fIndex]\n",
        "  }\n",
        "  ordered.vars <- order(R, decreasing=T) \n",
        "  var.names<-colnames(x)[ordered.vars]\n",
        "  return( list(ordered.names.list=var.names,ordered.features.list=ordered.vars,importance=sort(R,decreasing=T)) )\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "s6_ICXk2h1JZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test"
      ],
      "metadata": {
        "id": "Je1vi7_iRu0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "crea.ruido.unif<-function(n=100,d=2){\n",
        "  x<-runif(2*n*d,min=-1)\t#genero los datos\n",
        "  dim(x)<-c(2*n,d)\n",
        "  return(cbind(as.data.frame(x),y=factor(rep(c(-1,1),each=n))))\t#le agrego la clase\n",
        "}\n",
        "\n",
        "#datosA\n",
        "d<-10\n",
        "n<-20\n",
        "datos<-crea.ruido.unif(n=n,d=d)\n",
        "\n",
        "#tomar 50% de los datos al azar, y hacer que la clase sea el signo de la 8 variable\n",
        "shuffle<-sample(1:dim(datos)[1])\n",
        "sub<-shuffle[1:dim(datos)[1]*0.5]\n",
        "datos[sub,d+1]<-sign(datos[sub,8])\n",
        "#tomar 20% de los datos al azar (fuera de los anteriores), y hacer que la clase sea el signo de la 6 variable\n",
        "sub<-shuffle[(dim(datos)[1]*0.5):(dim(datos)[1]*0.7)]\n",
        "datos[sub,d+1]<-sign(datos[sub,6])\n",
        "#tomar 10% de los datos al azar, y hacer que la clase sea el signo de la 4 variable\n",
        "sub<-shuffle[(dim(datos)[1]*0.7):(dim(datos)[1]*0.8)]\n",
        "datos[sub,d+1]<-sign(datos[sub,4])\n",
        "#tomar 5% de los datos al azar, y hacer que la clase sea el signo de la 2 variable\n",
        "sub<-shuffle[(dim(datos)[1]*0.8):(dim(datos)[1]*0.85)]\n",
        "datos[sub,d+1]<-sign(datos[sub,2])\n",
        "datos[,d+1]<-factor(datos[,d+1])\n",
        "\n",
        "datosA<-datos\n",
        "#print(dim(datosA))\n",
        "#print(matrix(0,dim(datosA)[1],1))\n",
        " 1:(10-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "L2wYpiq6RwUv",
        "outputId": "beac524a-a1be-4d23-b34d-91599a19ca9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li><li>6</li><li>7</li></ol>\n"
            ],
            "text/markdown": "1. 1\n2. 2\n3. 3\n4. 4\n5. 5\n6. 6\n7. 7\n\n\n",
            "text/latex": "\\begin{enumerate*}\n\\item 1\n\\item 2\n\\item 3\n\\item 4\n\\item 5\n\\item 6\n\\item 7\n\\end{enumerate*}\n",
            "text/plain": [
              "[1] 1 2 3 4 5 6 7"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#install.packages(\"randomForest\", dependencies = T)\n",
        "#library(randomForest)\n",
        "#install.packages(\"kernlab\", dependencies = T)\n",
        "#library(kernlab)\n",
        "#library(MASS)\n",
        "\n",
        "#demo: aplicar el wrapper a los datos de iris\n",
        "data(iris)\n",
        "#FORW.rf <-forward.ranking(iris[,-5],iris[,5],method=\"rf.est\" ,tot.trees=100,equalize.classes=F)\n",
        "#FORW.lda<-forward.ranking(iris[,-5],iris[,5],method=\"lda.est\")\n",
        "#print(FORW.lda)\n",
        "\n",
        "#BACK.rf <-backward.ranking(iris[,-5],iris[,5],method=\"rf.est\" ,tot.trees=100,equalize.classes=F)\n",
        "#BACK.lda<-backward.ranking(iris[,-5],iris[,5],method=\"lda.est\")\n",
        "no.parametrico(iris[,-5],iris[,5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "id": "w34ux8tWW5a_",
        "outputId": "146f6c7e-2f4c-4e51-ac3e-ab94305fbe70"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<dl>\n",
              "\t<dt>$ordered.names.list</dt>\n",
              "\t\t<dd><style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>'Petal.Width'</li><li>'Petal.Length'</li><li>'Sepal.Length'</li><li>'Sepal.Width'</li></ol>\n",
              "</dd>\n",
              "\t<dt>$ordered.features.list</dt>\n",
              "\t\t<dd><style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>4</li><li>3</li><li>1</li><li>2</li></ol>\n",
              "</dd>\n",
              "\t<dt>$importance</dt>\n",
              "\t\t<dd><style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>131.185379740245</li><li>130.411048579772</li><li>96.9374360006482</li><li>63.5711461041639</li></ol>\n",
              "</dd>\n",
              "</dl>\n"
            ],
            "text/markdown": "$ordered.names.list\n:   1. 'Petal.Width'\n2. 'Petal.Length'\n3. 'Sepal.Length'\n4. 'Sepal.Width'\n\n\n\n$ordered.features.list\n:   1. 4\n2. 3\n3. 1\n4. 2\n\n\n\n$importance\n:   1. 131.185379740245\n2. 130.411048579772\n3. 96.9374360006482\n4. 63.5711461041639\n\n\n\n\n\n",
            "text/latex": "\\begin{description}\n\\item[\\$ordered.names.list] \\begin{enumerate*}\n\\item 'Petal.Width'\n\\item 'Petal.Length'\n\\item 'Sepal.Length'\n\\item 'Sepal.Width'\n\\end{enumerate*}\n\n\\item[\\$ordered.features.list] \\begin{enumerate*}\n\\item 4\n\\item 3\n\\item 1\n\\item 2\n\\end{enumerate*}\n\n\\item[\\$importance] \\begin{enumerate*}\n\\item 131.185379740245\n\\item 130.411048579772\n\\item 96.9374360006482\n\\item 63.5711461041639\n\\end{enumerate*}\n\n\\end{description}\n",
            "text/plain": [
              "$ordered.names.list\n",
              "[1] \"Petal.Width\"  \"Petal.Length\" \"Sepal.Length\" \"Sepal.Width\" \n",
              "\n",
              "$ordered.features.list\n",
              "[1] 4 3 1 2\n",
              "\n",
              "$importance\n",
              "[1] 131.18538 130.41105  96.93744  63.57115\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "id": "Vk5s27pb5iMM",
        "outputId": "798ae2fe-574d-4c5f-cd15-2ae12bd515cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     [,1] [,2] [,3] [,4] [,5]\n",
            "[1,]   NA   NA   NA   NA   NA\n",
            "[1] 1 1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "ignored",
          "traceback": [
            "Error in m[1, 1] <- k: number of items to replace is not a multiple of replacement length\nTraceback:\n"
          ]
        }
      ]
    }
  ]
}